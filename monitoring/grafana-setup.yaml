apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana-sa
  namespace: cnpg-cluster-test
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: cnpg-cluster-test
data:
  datasource.yaml: |
    apiVersion: 1
    datasources:
    - name: OpenShift-Prometheus
      type: prometheus
      url: https://thanos-querier.openshift-monitoring.svc.cluster.local:9091
      access: proxy
      isDefault: true
      jsonData:
        httpHeaderName1: 'Authorization'
        tlsSkipVerify: true
      secureJsonData:
        # Dieser Trick liest den Token direkt aus dem Pod-Dateisystem
        httpHeaderValue1: 'Bearer ${TOKEN}'
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: cnpg-cluster-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      serviceAccountName: grafana-sa
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
        env:
        # Hier wird der Token für die ConfigMap verfügbar gemacht
        - name: TOKEN
          valueFrom:
            secretKeyRef:
              name: grafana-sa-token # Achtung: Siehe Hinweis unten
              key: token
              optional: true
        # Falls kein Secret-Token da ist (K8s >1.24), nutzen wir den gemounteten Pfad
        volumeMounts:
        - name: datasource-config
          mountPath: /etc/grafana/provisioning/datasources
        - name: sc-dashboard-volume
          mountPath: /tmp/dashboards  
        - name: dashboard-provider-config
          mountPath: /etc/grafana/provisioning/dashboards/provider.yaml
          subPath: provider.yaml
      - name: grafana-sc-dashboard
        image: kiwigrid/k8s-sidecar:latest
        env:
        - name: METHOD
          value: WATCH
        - name: LABEL
          value: grafana_dashboard
        - name: FOLDER
          value: /tmp/dashboards
        - name: RESOURCE
          value: configmap
        volumeMounts:
        - name: sc-dashboard-volume
          mountPath: /tmp/dashboards
      volumes:
      - name: sc-dashboard-volume
        emptyDir: {}    
      - name: datasource-config
        configMap:
          name: grafana-datasources
      - name: dashboard-provider-config
        configMap:
          name: grafana-dashboard-provider
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: cnpg-cluster-test
spec:
  ports:
  - port: 3000
    targetPort: 3000
  selector:
    app: grafana
---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: grafana
  namespace: cnpg-cluster-test
spec:
  to:
    kind: Service
    name: grafana
  port:
    targetPort: 3000
  tls:
    termination: edge # Ermöglicht HTTPS-Zugriff auf Grafana
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-sa-token
  namespace: cnpg-cluster-test
  annotations:
    kubernetes.io/service-account.name: grafana-sa
type: kubernetes.io/service-account-token
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: grafana-sidecar-role
  namespace: cnpg-cluster-test
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: grafana-sidecar-rolebinding
  namespace: cnpg-cluster-test
subjects:
- kind: ServiceAccount
  name: grafana-sa
  namespace: cnpg-cluster-test
roleRef:
  kind: Role
  name: grafana-sidecar-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-provider
  namespace: cnpg-cluster-test
data:
  provider.yaml: |
    apiVersion: 1
    providers:
    - name: 'SidecarDashboards'
      orgId: 1
      folder: 'CNPG'
      type: file
      disableDeletion: false
      editable: true
      options:
        path: /tmp/dashboards  # Hier hat das Sidecar die Datei abgelegt!